#!/usr/bin/env python3
"""Board Protocol: Query all AIs for strategic decision."""
import os
import json
import requests
from dotenv import load_dotenv
load_dotenv()

PROMPT = '''BOARD QUERY: Modal vs Railway - Platform Selection for Prospecting Engine

## Context
Building a prospecting + email engine. Need to choose the right platform.

**User Experience:**
- Used Modal before (5 CRONs) and it "crashed a lot"
- Wants more stable architecture

## Our Requirements

1. **Prospecting Worker** - Scrape Google Maps every 6 hours
2. **Enrichment Worker** - Run website audits every 2 hours
3. **Email Engine** - Trigger outreach every 30 minutes
4. **Webhook Handler** - Receive GHL events in real-time
5. **Heartbeat** - Health monitoring */5 min
6. **Warmup** - Email reputation daily

## Current State
- Modal: 5 CRON limit, 8 endpoint limit (Starter plan)
- Already have 3 Modal CRONs working (heartbeat, outreach, warmup)
- Already have Railway account

## BOARD QUESTIONS:

### 1. WHY IS RAILWAY MORE STABLE?
- What makes Railway more reliable than Modal?
- Is this actually true or perception?
- What are each platform's failure modes?

### 2. WHY WAS MODAL SUGGESTED INITIALLY?
- What are Modal's advantages?
- When is Modal the right choice?
- Why did the board recommend Modal before?

### 3. CAN RAILWAY DO EVERYTHING WE NEED?
- Cron jobs (scheduled tasks)
- Long-running workers
- Webhooks (always-on endpoints)
- Web scraping with Playwright/Puppeteer
- Database connections

### 4. PLATFORM COMPARISON

Compare these specific aspects:
- Stability/uptime
- Cron job support
- Cold start times
- Timeout limits
- Cost at our scale
- Deployment complexity
- Debugging/logs
- Scalability

### 5. FINAL RECOMMENDATION

For OUR specific use case (prospecting + email engine):
- Which platform should we use?
- Should we hybrid (some Modal, some Railway)?
- Or go 100% one platform?

Give me a CLEAR recommendation with reasoning.
'''

def query_claude():
    api_key = os.getenv("ANTHROPIC_API_KEY")
    if not api_key:
        return {"ai": "Claude", "raw": "ERROR: No ANTHROPIC_API_KEY"}
    try:
        response = requests.post(
            "https://api.anthropic.com/v1/messages",
            headers={
                "x-api-key": api_key,
                "anthropic-version": "2023-06-01",
                "content-type": "application/json",
            },
            json={
                "model": "claude-sonnet-4-20250514",
                "max_tokens": 2500,
                "messages": [{"role": "user", "content": PROMPT}],
            },
            timeout=120,
        )
        data = response.json()
        return {"ai": "Claude", "raw": data.get("content", [{}])[0].get("text", str(data))}
    except Exception as e:
        return {"ai": "Claude", "raw": f"ERROR: {e}"}

def query_grok():
    api_key = os.getenv("GROK_API_KEY") or os.getenv("XAI_API_KEY")
    if not api_key:
        return {"ai": "Grok", "raw": "ERROR: No GROK_API_KEY or XAI_API_KEY"}
    try:
        response = requests.post(
            "https://api.x.ai/v1/chat/completions",
            headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
            json={"model": "grok-3-latest", "messages": [{"role": "user", "content": PROMPT}]},
            timeout=120,
        )
        data = response.json()
        return {"ai": "Grok", "raw": data.get("choices", [{}])[0].get("message", {}).get("content", str(data))}
    except Exception as e:
        return {"ai": "Grok", "raw": f"ERROR: {e}"}

def query_gemini():
    api_key = os.getenv("GEMINI_API_KEY")
    if not api_key:
        return {"ai": "Gemini", "raw": "ERROR: No GEMINI_API_KEY"}
    try:
        response = requests.post(
            f"https://generativelanguage.googleapis.com/v1beta/models/gemini-2.0-flash:generateContent?key={api_key}",
            headers={"Content-Type": "application/json"},
            json={"contents": [{"parts": [{"text": PROMPT}]}]},
            timeout=120,
        )
        data = response.json()
        return {"ai": "Gemini", "raw": data.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", str(data))}
    except Exception as e:
        return {"ai": "Gemini", "raw": f"ERROR: {e}"}

def query_chatgpt():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        return {"ai": "ChatGPT", "raw": "ERROR: No OPENAI_API_KEY"}
    try:
        response = requests.post(
            "https://api.openai.com/v1/chat/completions",
            headers={"Authorization": f"Bearer {api_key}", "Content-Type": "application/json"},
            json={"model": "gpt-4o", "messages": [{"role": "user", "content": PROMPT}]},
            timeout=120,
        )
        data = response.json()
        return {"ai": "ChatGPT", "raw": data.get("choices", [{}])[0].get("message", {}).get("content", str(data))}
    except Exception as e:
        return {"ai": "ChatGPT", "raw": f"ERROR: {e}"}

if __name__ == "__main__":
    from concurrent.futures import ThreadPoolExecutor
    print("Querying Board: Operational Excellence...")
    
    with ThreadPoolExecutor(max_workers=4) as executor:
        futures = [
            executor.submit(query_claude),
            executor.submit(query_grok),
            executor.submit(query_gemini),
            executor.submit(query_chatgpt),
        ]
        results = [f.result() for f in futures]
    
    with open("board_call_raw.json", "w") as f:
        json.dump(results, f, indent=2)
    
    for r in results:
        print(f"=== {r['ai']} ===")
        print(r['raw'][:2000] + "..." if len(r['raw']) > 2000 else r['raw'])
    
    print("\n=== DONE ===")
